{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4b7ae2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\OneDrive - UNIVERSITAS INDONESIA\\COOLYEAH\\smt 8\\tugas akhir\\topic-modelling\\env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic \n",
    "from sklearn.datasets import fetch_20newsgroups \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_01 = pd.read_csv('data/stemmed_merged_kubu_01.csv')\n",
    "df_02 = pd.read_csv('data/stemmed_merged_kubu_02.csv')\n",
    "df_03 = pd.read_csv('data/stemmed_merged_kubu_03.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train the BERTopic model (using multilingual model for Indonesian)\n",
    "topic_model = BERTopic(language=\"multilingual\", \n",
    "                       calculate_probabilities=True,\n",
    "                       min_topic_size=5,  # Minimum number of documents per topic\n",
    "                       nr_topics=\"auto\")  # Let BERTopic decide the optimal number\n",
    "\n",
    "# Train the model\n",
    "topics, probs = topic_model.fit_transform(df_01['full_text'].tolist())\n",
    "\n",
    "# Get an overview of the topics\n",
    "topic_info = topic_model.get_topic_info()\n",
    "print(\"\\nTopic Information:\")\n",
    "print(topic_info.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the top topics with their keywords\n",
    "print(\"\\nTop Words per Topic:\")\n",
    "for topic_id, words in topic_model.get_topics().items():\n",
    "    if topic_id != -1:  # -1 is the outlier topic\n",
    "        words_str = \", \".join([word[0] for word in words[:10]])\n",
    "        print(f\"Topic {topic_id}: {words_str}\")\n",
    "\n",
    "# Get document distribution across topics\n",
    "topic_distribution = pd.Series(topics).value_counts()\n",
    "print(\"\\nDocument distribution across topics:\")\n",
    "print(topic_distribution.head(10))\n",
    "\n",
    "# Add topic labels to the original data\n",
    "df_01['topic'] = topics\n",
    "df_01['topic_probability'] = [prob.max() for prob in probs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Topic word clouds\n",
    "def plot_topic_wordcloud(topic_model, topic_id, title):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    # Get words and weights\n",
    "    words = [word[0] for word in topic_model.get_topic(topic_id)]\n",
    "    weights = [word[1] for word in topic_model.get_topic(topic_id)]\n",
    "    \n",
    "    # Create frequency dictionary\n",
    "    word_freq = {words[i]: weights[i] for i in range(len(words))}\n",
    "    \n",
    "    # Generate word cloud\n",
    "    wordcloud = WordCloud(width=800, height=400, \n",
    "                         background_color='white',\n",
    "                         colormap='viridis').generate_from_frequencies(word_freq)\n",
    "    \n",
    "    # Display wordcloud\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis('off')\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Create word clouds for top 3 topics\n",
    "for i in range(3):\n",
    "    if i in topic_model.get_topics():\n",
    "        fig = plot_topic_wordcloud(topic_model, i, f\"Topic {i} Word Cloud\")\n",
    "        plt.show()\n",
    "\n",
    "# Plot interactive topic visualizations\n",
    "topic_vis = topic_model.visualize_topics()\n",
    "topic_vis.show()\n",
    "\n",
    "# Plot hierarchical clustering of topics\n",
    "hierarchy_vis = topic_model.visualize_hierarchy()\n",
    "hierarchy_vis.show()\n",
    "\n",
    "# Plot topic similarity heatmap\n",
    "heatmap_vis = topic_model.visualize_heatmap()\n",
    "heatmap_vis.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get representative documents for top topics\n",
    "print(\"\\nRepresentative tweets for top topics:\")\n",
    "top_topics = [t for t in topic_distribution.index if t != -1][:5]\n",
    "\n",
    "for topic_id in top_topics:\n",
    "    print(f\"\\n--- Topic {topic_id} ---\")\n",
    "    rep_docs = topic_model.get_representative_docs(topic_id)\n",
    "    for i, doc in enumerate(rep_docs[:3]):  # Show first 3 documents\n",
    "        print(f\"{i+1}. {doc[:200]}...\")  # Truncate long tweets"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
